modelopt_version,gpu_name,model_name,quantization_format,framework_name,framework_version,test_status,log_path
0.39.0,L40s,Llama-3.1-8B-Instruct,fp8,TensorRT-LLM,0.13.0,passed,logs/L40s/inference/Llama-3.1-8B-Instruct_fp8.log
0.39.0,L40s,Llama-3.1-8B-Instruct,int8_sq,TensorRT-LLM,0.13.0,passed,logs/L40s/inference/Llama-3.1-8B-Instruct_int8_sq.log
0.39.0,L40s,Llama-3.1-8B-Instruct,int4_awq,TensorRT-LLM,0.13.0,passed,logs/L40s/inference/Llama-3.1-8B-Instruct_int4_awq.log
0.39.0,L40s,Llama-3.1-8B-Instruct,w4a8_awq,TensorRT-LLM,0.13.0,passed,logs/L40s/inference/Llama-3.1-8B-Instruct_w4a8_awq.log
0.39.0,L40s,Phi-4,fp8,TensorRT-LLM,0.13.0,passed,logs/L40s/inference/Phi-4_fp8.log
0.39.0,L40s,Phi-4,int8_sq,TensorRT-LLM,0.13.0,passed,logs/L40s/inference/Phi-4_int8_sq.log
0.39.0,L40s,Phi-4,int4_awq,TensorRT-LLM,0.13.0,failed,logs/L40s/inference/Phi-4_int4_awq.log
0.40.0,L40s,Llama-3.1-8B-Instruct,fp8,TensorRT-LLM,0.14.0,passed,logs/L40s/inference/Llama-3.1-8B-Instruct_fp8_040.log
0.40.0,L40s,Llama-3.1-8B-Instruct,int8_sq,TensorRT-LLM,0.14.0,passed,logs/L40s/inference/Llama-3.1-8B-Instruct_int8_sq_040.log
0.40.0,L40s,Llama-3.1-8B-Instruct,int4_awq,TensorRT-LLM,0.14.0,failed,logs/L40s/inference/Llama-3.1-8B-Instruct_int4_awq_040.log
0.40.0,L40s,Llama-3.1-8B-Instruct,w4a8_awq,TensorRT-LLM,0.14.0,passed,logs/L40s/inference/Llama-3.1-8B-Instruct_w4a8_awq_040.log
0.40.0,L40s,Phi-4,fp8,TensorRT-LLM,0.14.0,passed,logs/L40s/inference/Phi-4_fp8_040.log
0.40.0,L40s,Phi-4,int8_sq,TensorRT-LLM,0.14.0,passed,logs/L40s/inference/Phi-4_int8_sq_040.log
0.40.0,L40s,Phi-4,int4_awq,TensorRT-LLM,0.14.0,passed,logs/L40s/inference/Phi-4_int4_awq_040.log
0.40.0,L40s,Phi-4,w4a8_awq,TensorRT-LLM,0.14.0,passed,logs/L40s/inference/Phi-4_w4a8_awq_040.log

